# 데이터 전처리
## 전처리의 필요성
- 모델 input 시 문제 발생
  - 누락 데이터
    - NaN -> 누락된 값을 포함한 행 drop, 누락된 값을 변환
    ```python
    df.isnull().sum() # 각 칼럼 별로 NaN 값이 있는 합이 나옴
    df.dropna(axis = 0) # NaN 포함한 행 없애기
    df.dropna(axis = 1) # NaN 포함한 열 없애기
    df.fillna(value) # NaN에 값 고정해서 넣기
    df['~'] = df['~'].fillna(df['~'].mean()) 
    df['~'] = df['~'].fillna(df.mean()) # 각 칼럼에 해당하는 평균 값 자동으로 할당 
    ```
  - 결측치, 잘못된 값
  - 중복되는 값
    ```python
    df.drop_duplicates(keep='first, last')
    ```
# Model
## 모형의 분류
- 예측해야하는 값이 실수인가
  - Y : 회귀
  - N : 분류
- 정답을 알고 있는 데이터인가
  - Y : 지도학습
  - N : 비지도학습
- patameter로 모델 표현이 가능한가
  - Y : parametric method
  - N : Non-parametric Method
- --
## 비용
- 비용 : 현재 parameter로 주어진 데이터를 얼마나 잘 표현했는가를 측정한 함수(비교)
  - y : 데이터의 실제 레이블 값
  - $\hat{y}$ : 현재 회귀식을 통해 예측한 값
  - $cost = f(y,\hat(y))=\sum_{i=1}^{n} (y^i - \hat{y}^i)^2$
  - cost를 통해 주어진 데이터로 방정식을 구하고 $\theta_0$, $\theta_1$에 대해 각각 미분한 뒤 연립 -> 최적의 parameter
- --
## 기존 선형회귀 모형의 가정
- 서로 다른 변수 간에 독립적 (독립성)
- 독립변수의 증가에 따라 종속변수 비례하여 바뀜 (선형성)
## 선형회귀의 확장
- 독립성을 제거하여 feature 개수를 줄인다
  - feature 개수가 줄면 학습효과가 더 명확, over-fitting이 덜 일어남
- 선형성을 제거해 다차식 관계로 더 유연한 회귀선을 나타낼 수 있다.
---
## 범주형 변수의 처리
- 독립변수 2개
  > ex) 남 : 1, 여 : 0 과 같이 표현하는 방법이 있다
- 3개일 떄 ?? (one-hot enoding)

# 데이터의 종류
## 실수형 값
## 범주형 값
- 변수 내의 서로 다른 값이 서로 다른 의미이나 비교가 불가능
  - `dummy varuable`을 만들어 비교한다 (`one-hot encodding`)
    - 범주가 두 가지로 나뉠 때만 가능
  - Ex) 남자 -> 1, 여자 -> 0
  - 수치로 변경 했을 때 서로 간의 관계성을 없애기 위해 dummmy를 만들어 관계성을 없애준다.
# 변수의 표준화
- 변수 간에는 서로 다른 scale과 Unit을 가짐
- 특히 거리 기반의 ML을 쓸 때는 표준화 필요
  - mix-max scaling : 변수 내에서 1,0 사이에 값으로 나눔
  - standardize (표준화): 정규화함
## sklearn
- 파이썬에서 제공하는 표준화된 머신러닝 라이브러리
  - StandardScaler
  - MinMaxScaler

# 선형회귀모형의 한계 보완
- 비선형적으로 관계 표현 (`PolynomialFeatures`) 이용
  - 다차항 넣기
  - 변수 간에 상호작용 넣기

# 로지스틱 회귀모형
- 분류, 지도학습, parametric Method 
- 예측하고자 하는 범주 각각에 숫자 부여해 회귀분석 학습
## 분류문제에 선형회귀를 적용 시 문제점
- `범주형 종속변수`를 (0,1)로 바꾸고 선형회귀 학습 시 문제점
  - 예측된 값을 확률로 간주할 수 없음
  - 0 ~ 1 사이의 값을 벗어나는 경우 존재
## 문제해결을 위한 요구사항
- 종속변수(y)가 특정 레이블(ex : 합격, 불합격 )로 분류될 확률을 계산해야함
- 어떤 경우에도 종속변수는 0~1 사이의 값을 가지도록 모델링 되어야 함

## 로지스틱 함수 및 성질
- $$ f(x) = \frac{1}{1+e^{-x}} $$
  - 음의 무한대 : 0에 가까워짐
  - 양의 무한대 : 1에 가까워짐
  - > 확률값으로 표현이 가능하다
- `로지스틱 회귀` -> `로지스틱 함수`를 `선형회귀`와 결합하여 특정 레이블로 분류될 확률을 예측하는 모형 

## 로지스틱 회귀 모형의 가정
i번째 데이터 
$$ x^{i} $$
에 대하여 
$$ y^{i} = 1 $$
일 확률을 다음과 같이 계산
$$ f(x^{i}) = p(y^{i} = 1 | x^{i}) = \frac{1}{1+e^{-({\theta+\theta_1x^i})}} $$  
그 후 나온 값으로 의사결정을 함
## 로지스틱 회귀 - 비용(cost)의 정의
$$ J(\theta_0, \theta_1) = -\frac{1}{m}\sum_{i=1}^{m}[(y^{i}logf(x^{i})+(1-y^i)log(1-f(x^i))] $$
> 데이터를 올바르게 분류한다 -> 비용함수가 낮아져야 하므로 -log함수를 취한다  
> y가 1, 0일 때의 경우를 나누어 비용함수 생각
>> y가 1일 때 확률이 1에 가까워질 수록 비용함수 낮아짐, 0일 때 반대
## 로지스틱 회귀 프로세스
1. 범주형 데이터를 수치형으로 변경 
2. 선형회귀모형을 통해 y_hat 값을 구함
3. 로지스틱 함수에 넣어서 확률을 구함
4. 해당 확률을 통해 의사결정
## 로지스틱 회귀함수의 확장
- 독립변수 개수 확장 가능
- 독립성 가정 제거해 변수 사이 상호작용 표현
- 선형성 가정 제거해 다차식 관계 표현 