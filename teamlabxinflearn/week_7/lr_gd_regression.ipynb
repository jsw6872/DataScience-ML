{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 학습 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning ( 지도학습 )\n",
    "훈련 데이터로부터 하나의 함수를 유추"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent based learning\n",
    "- Probability theory based learning\n",
    "- Information theroy based learning\n",
    "- Distance similarity based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent based learning\n",
    "- 실제 값과 학습된 모델 예측치의 오차 최소화\n",
    "- 모델의 최적 parameter 찾기가 목적\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측치 : $ \\hat{y} = ax + b $  \n",
    "실제 관측치 : $ y = ax + b + e $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost function : 실제값과 가설함수 차이\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost function\n",
    "![cost function](../img/cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights의 최적값 컴퓨터가 찾는 방법\n",
    "- 연립방정식 풀기\n",
    "- gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normal equation](../img/normal_equation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normal equation](../img/normal_equation_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w_0 는 상수항의 weight, w_1 은 x 계수의 weight $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iteration 등의 사용자 지정 Parameter가 없음  \n",
    "- Feature 가 많아지면 계산 속도가 느려짐\n",
    "- 역행렬이 존재하지 않을 경우 사용 못 함 ( 가우스 소거 시 0인 행, 열이 존재)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 구간의 경사값이 0이 되는 지점을 찾는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ x_{new} = x_{old} - \\alpha \\times (f(x_{old})') $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "derivative = []\n",
    "y = []\n",
    "for i in range(100): # iterator 횟수 사용자가 지정해줘야 함\n",
    "    old_value = x\n",
    "    y.append(old_value ** 2) # x^2 \n",
    "    derivative.append(old_value - 0.01 * 2 * old_value) # 0.01도 사용자 지정\n",
    "    x = old_value - 0.01 * 2 * old_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning rate 과 loop에 따라 달라짐\n",
    "- learning rate 작을 경우\n",
    "  - loop이 충분하지 못 할 경우 최적값에 도달 못 함\n",
    "- learning rate 클 경우\n",
    "  - 최적값을 못 찾고 데이터가 튀어서 수렴을 못 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linear regression with GD](../img/linear_regression.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "451282c7329e2a6a364ca3aa9d61cbc27edaeb5d17f404c45e9cca05e3b54b52"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('da')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
