{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![full_gd](../../img/full_batch_gd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Local Optimize point(지역 최적점)에 빠지지않게 방지,\n",
    "헤어나오기 위해 모든 Data를 모아놨다가 한꺼번에 처리하는 방법\n",
    "\n",
    "- GD는 1개의 데이터를 기준으로 미분\n",
    "\n",
    "- But 일반적으로 GD = (full) batch GD라고 가정\n",
    "- 모든 데이터 셋으로 학습\n",
    "- 업데이트 감소 -> Single GD보다 계산상 효율적(속도) 가능\n",
    "- 안정적인 Cost 함수 수렴\n",
    "\n",
    "한계\n",
    "- 지역 최적화 가능\n",
    "- 메모리 문제 (ex - 30억개의 Data를 한번에 처리할 경우 쓰기 힘듦)\n",
    "- 대규모 Dataset  모델/Parameter 업데이트가 느려짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### procedure SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. shuffle Data\n",
    "2. data 1개씩 GD 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점\n",
    "  - 모델 성능 및 개선 속도 확인 가능\n",
    "  - 일부 문제에 대해 더 빨리 수렴\n",
    "  - 지역 최적화 회피  \n",
    "- 단점\n",
    "  - 대용량 데이터 시 시간이 오래걸림\n",
    "  - 더이상 cost가 줄어들지 않는 시점 발견의 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch (Stochastic) Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 데이터에서 일부 뽑아서 사용\n",
    "- 한번의 일정량의 데이터를 랜덤하게 뽑아서 학습\n",
    "- SGD와 Full-Batch GD를 혼합한 기법\n",
    "- 가장 일반적으로 많이 쓰이는 기법\n",
    "- GD -> SGD -> Mini-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알아야할 개념\n",
    "- Epoch\n",
    "  - 전체 데이터가 Training 데이터에 들어갈 때 카운킹 되는 횟수 (전체 데이터가 한번 다 들어가면 1epoch)\n",
    "  - Full-batch를 n번 실행하면 n epoch\n",
    "- Batch\n",
    "  - 데이터를 잘라서 사용할 때 그 자른 것의 개수가 `Batch-size`\n",
    "> 5120개의 Data에 512 batch-size라면 10번 학습을 해야 1epochb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### procedure of Mini-Batch-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 섞기\n",
    "2. 배치사이즈를 통해 자른 범위만큼 반복\n",
    "3. 정해진 epoch만큼 1~2를 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate 의 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일정한 주기로 learning rate을 감소시키는 방법\n",
    "- 특정 epoch마다 learning rate 감소\n",
    "- Hypter-parameter 설정의 어려움\n",
    "- 지수 감수 및 1/t 감소 등이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종료조건 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGD과정에서 특정 값 이하로 cost function이 줄어들지 않기 때문이 종료조건을 설정해야함\n",
    "- 종료조건을 설정 : tol > (이번 cost functoin)loss - (이전 cost function) previous_loss\n",
    "- tol은 Hyper-parameter로 사람 설정"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "451282c7329e2a6a364ca3aa9d61cbc27edaeb5d17f404c45e9cca05e3b54b52"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('da')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
